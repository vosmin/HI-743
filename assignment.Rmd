---
title: "Linear Regression R"
author: "Vosmin Shaik"
date: "2025-02-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

install.packages("ISLR2")
library(ISLR2)
```

# Boston Dataset Analysis

### Objective

How can we predict the Median Value of Owner_Occupied Homes using the lower Status

\<what are we analyzing? Why? What insight can we gain from this analysis.

### Data Understand and preparation

\<What kinds of variables do we have? What kind of questions can we answer further with this data?\>

### Data Loading

\<What does the summary say about this date?\>

```{r load.data}
data(Boston)
glimpse(Boston)

summary(Boston)
```

### Data exploration

```{r missing values}
missing_values = Boston %>%
  summarise(across(everything(), ~ sum(is.na(.))))
print(missing_values)
```

### Train-Test Split

\<How does this technique aid our analysis, especially given new data?\>

```{r train-test}
set.seed(123) # For reproducibility
Boston_split = Boston %>%
  mutate(id = row_number()) %>%
  sample_frac(0.75)

Boston = Boston %>% mutate(id = row_number())

train_data = Boston_split
test_data = anti_join(Boston, Boston_split, by = "id") #Remaining 25%
```

### Exploratory Data Analysis

\<what figures did we build?Why? What information do they convey? How it is important to the analysis?\>

```{r histogram for medv}
ggplot(Boston, aes(x = medv)) +
  geom_histogram(fill = "steelblue", binwidth = 2, color = "white") +
  labs(title = "distribution of Median Home Values",
       x = "Median value ($1000s)",
       y = "Count")

```

```{r LSTAT vs MEDV Scatterplot}
ggplot(Boston, aes(x = lstat, y=medv)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: LSTAT vs. MEDV",
       x = "Lower Status Population",
       y = "Median Home Value ($1000s)")

```

### Model Implementation & Explanation

\<what model are we using? why does this/these model(s) apply to the data?What are the pros & cons of this type of model? \>

### Perform simple Linear Regression on Training Data

\<Describe the function & model fit. maybe talk about the evaluation metrics?\>

```{r Liunear Regression}
lm.fit = lm(medv ~ lstat, data = train_data)
summary(lm.fit)
```

Could built a scatter plot with this regression line onto it.

### Apply Model to Test Data

\<could interpret the Test MSE\>

```{r apply model to test_data}
train_mse = mean((train_data$medv - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

### Simple Linear Regression results & interpretation

\<Overall, how good is this fit? What does it say about the data and the question being asked?\>

### Perform Multiple Linear Regression on Training Data

\<what question does this model answer?\>

```{r}
lm.multiple.fit = lm(medv ~ lstat + age, data = train_data)  
summary(lm.multiple.fit)
```

### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$medv - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

## NHANES Data Analysis

## Objective

For those between the ages of **18-70**, this research attempts to predict **BMI** using **Age, Smoking Status (SmokeNow), and Physical Activity(PhysActive)**.

### 1.1 What are we analyzing?

We are looking at the effects of physical activity, smoking, and age on BMI.  Given that BMI is a crucial health indicator, knowing these correlations can aid in determining the causes of weight fluctuations and general health hazards.

### 1.2 why are we conducting this analysis?

**Diabetes, heart disease, and hypertension** are among the health hazards linked to an increased BMI.  While physical activity is essential for controlling weight, smoking can affect appetite and metabolism.  We can gain a better understanding of how lifestyle decisions affect BMI variances and general health by looking at these links.

### 1.3 What insights can we gain ?

This analysis looks at **how BMI is affected by age, smoking habits, and physical activity. The goal is to understand how these factors influence body weight**. The results could help create personalized health plans and support public health efforts to encourage healthier living.

## 2 Data understanding & Preparation

### 2.1 Variables in the Dateset:

- BMI: This is the main value we're trying to predict. It tells us a person's body weight in relation to their height.
- Age: The person's age, between 18 and 70 years old.
- SmokeNow: Shows whether the person currently smokes (Yes or No).
- PhysActive: Shows if the person is physically active (Yes or No).

### 2.2 Key questions we can answer:

- Does BMI increase or decrease with age?
- Is there a noticeable difference in BMI between people who smoke and those who don’t?
- How does being physically active affect a person’s BMI?

## 3 Data loading

We’re using data from the NHANES package, which includes health info like BMI, age, smoking habits, and physical activity. By looking at a summary of this data, we can see how these values are spread out, check for anything missing, and spot anything unusual. This helps us make sure the data is clean and reliable before we start analyzing it.


```{r}
#install.packages("NHANES")
library(NHANES)
data(NHANES)

SMOKERS = NHANES %>%
  select(BMI, Age, SmokeNow, PhysActive) %>%
  filter(Age >= 18 & Age <= 70)
```

## 4 Data Exploration

```{r}
missing_values <- SMOKERS %>%
  summarise(across(everything(), ~ sum(is.na(.))))

print(missing_values)
```

## 5. handling missing data.

We handle missing data to avoid bias, loss of information, and 
poor model performance, ensuring accurate and reliable analysis

```{r}
# Remove rows with missing or non-finite values
SMOKERS <- SMOKERS %>%
  filter(!is.na(BMI) & !is.na(Age) & !is.na(SmokeNow) & !is.na(PhysActive))

# Confirm data cleaning
print(nrow(SMOKERS))  # Remaining rows after cleaning
```

## 6. Train - Test Split

We split the data into **two parts — 75% for training and 25% for testing** — so we can see how well our model works on new, unseen data. The training part helps the model learn, and the testing part checks if it can make good predictions. This way, we make sure the model isn’t just memorizing the data, but actually learning useful patterns.

```{r}
set.seed(123)
SMOKERS <- SMOKERS %>% mutate(id = row_number())

SMOKERS_split <- SMOKERS %>%
  sample_frac(0.75)  # 75% for training data

# The remaining data will be for testing.

test_data <- anti_join(SMOKERS, SMOKERS_split, by = "id") 
train_data <- SMOKERS_split
```

## 7 Exploratory Data Analysis

We use histograms, box plots, and scatter plots to understand how the data is spread out, find relationships between variables, and identify patterns. These visuals help guide our analysis.

```{r}
library(ggplot2)

ggplot(SMOKERS, aes(x = BMI)) +
  geom_histogram(fill = "steelblue", binwidth = 5, color = "white") +
  labs(title = "Distribution of BMI", x = "BMI", y = "Count")
```

### 7.1 Scatterplot: Age vs. BMI

This helps in visualizing the relationship between **Age** and **BMI**.

```{r}
ggplot(SMOKERS, aes(x = Age, y = BMI)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: Age vs. BMI", x = "Age", y = "BMI")
```

### 7.2 Scatterplot: SmokeNow vs. BMI

A scatterplot of SmokeNow vs. BMI shows how smoking status relates to body weight, making it easier to spot any patterns or connections between the two.

```{r}
ggplot(SMOKERS, aes(x = SmokeNow, y = BMI)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Boxplot: SmokeNow vs. BMI", x = "SmokeNow", y = "BMI")
```

## Model Implementation

We use **Simple Linear Regression** because it's a quick and easy way to predict a continuous value using just one variable. It's simple to apply and runs fast, but it can be affected by outliers and only works well if the relationship between the variables is actually linear.

### Perform simple Linear Regression on Training Data

Simple linear regression draws the best-fit line through the data by keeping the differences between actual and predicted values as small as possible. We measure how well the model works using:

- **Mean Squared Error (MSE):** Shows how far off the predictions are from the actual values on average.
- **R-squared (R²):** Tells us how much of the variation in the target variable is explained by the model.

```{r}
lm.fit <- lm(BMI ~ Age, data = train_data)
summary(lm.fit)
```

### Apply Model to Text Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```

### Simple Linear Regression results & interpretation

- **Training MSE: 42.98**  
  The model has an average squared error of 42.98 on the training set, which shows it fits the data fairly well.

- **Test MSE: 34.98**  
  The model does a bit better on the test set with an error of 34.98, meaning it makes good predictions on new data.

- **Conclusion:**  
  The model fits reasonably well and doesn’t show signs of overfitting, since the training and test errors are close. Still, we could improve its performance by adding more variables or trying more advanced models.

### Perform Multiple Linear Regression on Training Data

```{r}
lm.multiple.fit = lm(BMI ~ Age + SmokeNow + PhysActive, data = train_data)  
summary(lm.multiple.fit)
```

### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.multiple.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))

```

### Multiple Linear Regression results & interpretation

- **Training MSE: 41.57**  
  The model's error on the training data is 41.57, which shows a decent fit but with some room to improve.

- **Test MSE: 33.69**  
  The model performs a bit better on the test data, with an error of 33.69, indicating it handles new data well.

- **Conclusion:**  
  The Multiple Linear Regression model fits better than the Simple Linear Regression since the test error is lower. It’s not overfitting and generalizes well, but the results could be improved by adding more predictors or using more advanced models.

